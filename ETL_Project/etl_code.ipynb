{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importing </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "import xmltodict\n",
    "import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> you also required two file paths that will be avalible globally in the code for all functions. these are <b> transformed_data.csv</b> to store the final output data that can be load to database and <b> log_file.txt</b> that stores all logs. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file=\"transformed_data.csv\"\n",
    "log_file=\"log_file.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Exract daat from multi sources </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>1. Extract data from csv file </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process):\n",
    "    df=pd.read_csv(file_to_process)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2. Extract data from json file </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process):\n",
    "    try:\n",
    "        df = pd.read_json(file_to_process, lines=True)\n",
    "        return df\n",
    "    except ValueError as e:\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3. Extract from xml </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process):\n",
    "   dataframe=pd.DataFrame(columns=['name','height','weight'])\n",
    "   \n",
    "   tree=et.parse(file_to_process)\n",
    "   root=tree.getroot()\n",
    "   for person in root:\n",
    "      name=person.find(\"name\").text\n",
    "      height = float(person.find(\"height\").text) \n",
    "      weight = float(person.find(\"weight\").text) \n",
    "      dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True) \n",
    "      return dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> create function to identify which function to call basis on file type of data file, which uses the glob method to identify file type </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(): \n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data \n",
    "     \n",
    "    # process all csv files \n",
    "    for csvfile in glob.glob(\"*.csv\"): \n",
    "        extracted_data = pd.concat([extracted_data, extract_from_csv(csvfile)], ignore_index=True) \n",
    "         \n",
    "    # process all json files \n",
    "    for jsonfile in glob.glob(\"*.json\"): \n",
    "        extracted_data = pd.concat([extracted_data, extract_from_json(jsonfile)], ignore_index=True) \n",
    "     \n",
    "    # process all xml files \n",
    "    for xmlfile in glob.glob(\"*.xml\"): \n",
    "        extracted_data = pd.concat([extracted_data, extract_from_xml(xmlfile)], ignore_index=True) \n",
    "         \n",
    "    return extracted_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Transform data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    '''Convert inches to meters and round off to two decimals \n",
    "    1 inch is 0.0254 meters '''\n",
    "    \n",
    "    data['height']=round(data.height*0.0254,2)\n",
    "    \n",
    "    '''Convert pounds to kilograms and round off to two decimals \n",
    "    1 pound is 0.45359237 kilograms '''\n",
    "    data['weight']=round(data.weight* 0.45359237,2)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Loading and Logging </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(target_file,transformed_data):\n",
    "    transformed_data.to_csv(target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>our need to implement the logging operation to record the progress of the different operations. For this operation, you need to record a message, along with its timestamp, in the log_file</p>\n",
    "\n",
    "<p> to record a message, needed to implement a function log_progress() that accepts the log message as an argument , capture the current date and time using datetime function from datetime library.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) #strftime attribute to convert the timestamp to a string format\n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "     name  height  weight\n",
      "0    alex    1.67   51.25\n",
      "1    ajay    1.82   61.91\n",
      "2   alice    1.76   69.41\n",
      "3    ravi    1.73   64.56\n",
      "4     joe    1.72   65.45\n",
      "5    alex    1.67   51.25\n",
      "6    ajay    1.82   61.91\n",
      "7   alice    1.76   69.41\n",
      "8    ravi    1.73   64.56\n",
      "9     joe    1.72   65.45\n",
      "10   alex    1.67   51.25\n",
      "11   ajay    1.82   61.91\n",
      "12  alice    1.76   69.41\n",
      "13   ravi    1.73   64.56\n",
      "14    joe    1.72   65.45\n",
      "15  simon    1.72   50.97\n",
      "16  simon    1.72   50.97\n",
      "17  simon    1.72   50.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GPU-TECH\\AppData\\Local\\Temp\\ipykernel_16772\\442833592.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, extract_from_csv(csvfile)], ignore_index=True)\n",
      "C:\\Users\\GPU-TECH\\AppData\\Local\\Temp\\ipykernel_16772\\2648932179.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
      "C:\\Users\\GPU-TECH\\AppData\\Local\\Temp\\ipykernel_16772\\2648932179.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
      "C:\\Users\\GPU-TECH\\AppData\\Local\\Temp\\ipykernel_16772\\2648932179.py:10: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract() \n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") \n",
    " \n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") \n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
